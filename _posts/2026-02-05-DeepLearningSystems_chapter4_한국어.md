---
title: 딥러닝 시스템 4장
author: khw
date: 2026-02-05
categories: [Study, DeepLearingSystems]
tags: [LAB]
pin: true
math: true
mermaid: true
---

## 제 4 장

## 모델 훈련

높은 통계적 성능을 달성하면서도 연산 및 전력 예산 내에서 모델을 훈련시키려면 여러 가지 설계 고려 사항이 필요합니다. 여기에는 토폴로지 정의, 데이터셋 준비, 적절한 모델 가중치 초기화, 최적화 알고리즘 및 목적 함수 선택, 모델 크기 축소, 훈련된 모델 평가 등이 포함됩니다. 훈련 과정은 연산 및 메모리 집약적일 수 있으며, 훈련 시간을 줄이고 메모리 병목 현상을 완화하기 위한 기술들이 이 장과 다음 두 장에 걸쳐 논의됩니다.

1.6절에서 훈련 단계를 소개했습니다. 검증 오차(validation error)가 특정 임계값 미만이거나 여러 번의 반복(iteration) 후에도 계속 감소하지 않으면 훈련이 중단됩니다. 검증 오차는 데이터 과학자가 선택한 $n$번의 훈련 반복마다 계산됩니다. 이는 모델이 배포되었을 때 어떻게 수행될지를 나타내는 지표로 사용됩니다.

역전파(backpropagation) 단계 동안 계산된 그래디언트(gradient)는 각 가중치가 비용(cost)에 기여하는 정도를 측정합니다. 비용(cost), 손실(loss), 페널티(penalty), 오차(error), 목적 함수(objective function)라는 용어는 때때로 상호 교환적으로 사용됩니다. 이 책에서 **손실**은 하나의 데이터 샘플에 대한 예상 출력과 실제 출력 간의 차이를 나타내는 지표이며, **비용**, **오차**, **목적 함수**는 샘플 배치(batch)에 대한 손실의 합을 동의어로 나타냅니다. 일반적인 목적 함수의 예로는 분류 및 회귀 작업을 위한 교차 엔트로피 오차(4.4절에서 논의)와 평균 제곱 오차(MSE)가 있습니다.

이 장의 나머지 부분에서는 낮은 훈련 오차와 낮은 테스트 오차를 달성하기 위해 모델을 훈련하는 방법을 자세히 설명합니다. 1.6절에 설명된 각 훈련 단계의 성능을 향상시키는 기술을 검토합니다. 불균형한 데이터셋 처리, 새로운 토폴로지 설계, 훈련 버그 해결, 기존의 사전 훈련된 모델 활용 등 숙련된 데이터 과학자들이 현업에서 사용하는 방법론을 제공합니다. 또한 메모리 병목 현상을 줄이는 방법에 대해서도 논의합니다. 훈련 시간을 줄이기 위한 분산 훈련 알고리즘은 6장에서 다룹니다. 1.10절에 소개된 표기법을 검토하면 이 장에 제시된 수식을 이해하는 데 도움이 될 것입니다.

## 4.1 훈련 데이터에서 프로덕션 데이터로의 일반화

잘 설계되고 훈련된 모델은 훈련 중에 사용되지 않은 프로덕션 데이터에서도 좋은 성능을 보입니다. 즉, 모델은 훈련 데이터셋에서 프로덕션 또는 테스트 데이터셋으로 **일반화(generalize)**됩니다. 구체적으로, 모델은 훈련 및 테스트 데이터셋 모두에서 낮은 오차율을 보입니다. 반대로 높은 테스트 오차율을 가진 모델은 신뢰할 수 없습니다. 이 섹션에서는 높은 테스트 오차율의 원인, 특히 과소적합(underfitting), 과적합(overfitting), 그리고 날카로운 최솟값(sharp minima)에 대해 설명하고, 이러한 오차를 줄이는 방법을 설명합니다. 빨간색 점은 모델의 예측을 나타냅니다.

그림 4.1: (a) 네 개의 훈련 샘플(파란색 점)과 하나의 검증 샘플(녹색 점). (b) 4차 다항식 함수는 훈련 오차가 0이지만 검증 오차가 높습니다. (c) 더 단순한 1차 다항식 함수는 낮은 검증 오차를 가집니다. 빨간색 점은 모델의 예측을 나타냅니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000000_fe6bbdaf1a1596f5dbe6da23071e4628909de5ae856380b8c40cdc7458ac0419.png)

**과소적합(Underfitting)**은 모델이 너무 적은 학습 능력을 가지고 있어 데이터의 일반적인 특성을 제대로 학습할 수 없을 때 발생합니다. 과소적합의 증상은 높은 훈련 오차와 높은 테스트 오차입니다. 과소적합을 완화하는 가장 좋은 기술은 더 복잡한 모델을 사용하는 것입니다. 딥러닝(DL)에서는 더 많은 레이어와 더 많은 가중치를 추가하여 토폴로지의 표현 용량을 늘리는 것을 의미합니다.

**과적합(Overfitting)**은 모델이 너무 많은 학습 능력을 가지고 있어 훈련 데이터 샘플의 노이즈나 훈련 세트에만 있는 특성까지 학습할 때 발생합니다. 과적합은 훈련 샘플이 불충분한 상태에서 거대한 모델을 사용할 때 발생합니다. 과적합의 증상은 낮은 훈련 오차와 높은 테스트 오차입니다. 그림 4.1은 간단한 ML 알고리즘인 선형 회귀를 사용한 1D 예제로 과적합을 보여줍니다. 그림 4.1a는 네 개의 훈련 샘플(파란색 점)과 훈련 중에 사용되지 않은 하나의 검증 샘플(녹색 점)을 보여줍니다. x축은 집 크기와 같은 특징(feature)이고, y축은 집 가격과 같은 레이블(label)입니다. 3차 이상의 다항식 함수는 4개의 훈련 데이터 포인트를 완벽하게 통과할 수 있습니다. 이 그림은 간단한 시각화를 위해 4차 다항식을 사용합니다. 그림 4.1b는 모델이 훈련 오차가 없지만 더 높은 검증 오차(빨간색 점과 녹색 점 사이의 거리의 제곱)를 가짐을 보여줍니다. 더 단순한 1차(아핀) 함수는 모든 훈련 데이터 포인트를 완벽하게 통과하지는 않지만, 그림 4.1c와 같이 낮은 검증 오차를 가집니다. 빨간색 점은 검증 샘플에 대해 각 모델이 예측한 것을 보여주며, 녹색 점은 해당 샘플에 대한 정답(ground truth)입니다. 복잡한 모델은 훈련 샘플에 과적합되었습니다. 단순한 모델에 비해 훈련 오차는 0이지만 검증 오차는 높습니다. 따라서 이 예시에서는 단순한 모델이 선호됩니다.

그림 4.2는 모델의 복잡성이 증가함에 따라 훈련 및 검증 오차에 어떤 일이 발생하는지 보여줍니다. 훈련 오차는 복잡성이 증가함에 따라 감소하지만, 검증 오차는 처음에는 감소하다가

그림 4.2: 모델 복잡성의 이상적인 수준은 검증 오차가 가장 낮은 지점입니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000001_6937f1eb7a38d69245e490459f4b68c863e26fe8f85ed5fe33ce4d6a6d9f9ac4.png)

증가합니다. 점선의 왼쪽 복잡성을 가진 모델은 과소적합이고, 점선의 오른쪽 복잡성을 가진 모델은 과적합입니다. 최적의 지점(sweet spot)은 바로 점선에 위치하며, 여기서 모델은 가장 낮은 검증 오차를 가집니다. 모델은 과소적합을 피할 만큼 충분히 복잡하지만 과적합을 피할 만큼 단순해야 합니다.

검증 오차는 모델이 프로덕션에 배포될 때 예상되는 오차를 나타내기 때문에 훈련 오차보다 훨씬 더 중요합니다. ML 이론에서 이러한 오차를 최소화하는 것을 **편향-분산 트레이드오프(bias-variance tradeoff)**라고 합니다. 높은 훈련 오차는 높은 편향(bias) 또는 과소적합을 나타냅니다. 높은 검증 오차와 낮은 훈련 오차는 높은 분산(variance) 또는 과적합을 나타냅니다. 해결책을 처방하기 전에 성능 저하의 원인(과적합 또는 과소적합)을 결정하는 것이 항상 중요합니다.

다양한 DL 토폴로지에 고유한 흥미롭고 반직관적인 현상은 그림 4.3 [NKB+20]에 묘사된 **이중 하강(deep double descent)**입니다. 토폴로지의 복잡성이 증가함에 따라(즉, 모델의 깊이가 깊어짐에 따라), 검증 오차는 처음에는 감소하다가 증가하는 예상 궤적을 따르지만, 그 후 다시 감소하기 시작합니다. 즉, 토폴로지의 크기를 늘리면 일부 시나리오에서 테스트 오차를 낮출 수 있습니다. 복잡한 모델은 과적합을 초래해야 하므로 정확한 이유는 잘 이해되지 않습니다. 잠정적인(다소 모호한) 이유는 매우 큰 토폴로지가 더 큰 솔루션 공간을 탐색하여 우수한 솔루션으로 이어질 수 있다는 것입니다. 이 현상과 권장 훈련 기술에 미치는 영향을 이해하는 것은 진행 중인 연구 분야입니다. 대부분의 실무자들은 이 현상을 안전하게 무시하거나 인지하지 못하고 있습니다.

일반화 성능 저하의 또 다른 원인은 **날카로운 최솟값(sharp minima)**일 수 있습니다 [HS97]. 이 가설은 경험적 증거에 기초합니다. 그림 4.4는 하나의 가중치 또는 특징(x축)만을 사용한 1D 장난감 예제로 직관을 설명합니다. 훈련에는 모델을 반복적으로 업데이트하고 훈련 오차가 더 낮은 솔루션 공간 영역으로 이동하는 과정이 포함됩니다. 훈련 비용 함수(파란색 실선)는 테스트 비용 함수(녹색 점선)와 유사하지만 약간 다릅니다. 이 차이는 테스트 샘플이 훈련 샘플과 유사하지만 동일하지 않기 때문입니다. 이 예에서 평평한 최솟값(flat minimum) 솔루션과 날카로운 최솟값 솔루션은 동일한 훈련 오차를 가지지만,

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000002_a9e8c23a739ed0d5812b99a719a7a614eef0c6a98e0b7766f031b37782287187.png)

그림 4.3: 일부 DL 토폴로지에서 관찰되는 이중 하강(deep double descent)의 예시; 복잡성이 증가함에 따라 검증 오차는 예상대로 감소했다가 증가하지만, 그 후 다시 감소하기 시작합니다. [NKB+20]에 기초함.

그림 4.4: 이 장난감 예제에서 테스트 데이터셋에 대한 비용 함수는 훈련 데이터셋에 대한 비용 함수에서 약간 이동되어 있습니다. 날카로운 최솟값 솔루션은 높은 테스트 오차를 가집니다. 평평한 최솟값은 작은 테스트 오차를 가집니다. [KMN+17]에 기초함.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000003_f5b024730697e47805ea7e6120d0fe8e1e296a22442db4626b1226832a893712.png)

다른 테스트 오차를 가집니다. 이러한 오차는 y축을 따라 $J(w)$로 표시됩니다. 평평한 최솟값 솔루션은 낮은 테스트 오차를 가지며, 날카로운 최솟값 솔루션은 높은 테스트 오차(녹색 점)를 가집니다. 평평함의 척도는 헤시안(Hessian)의 트레이스(trace)이며, 작은 트레이스는 평평한 최솟값을 나타냅니다 [DYC+19].

평평한 최솟값이 보이지 않는 데이터에 더 잘 일반화되지만, 날카로운 최솟값이 반드시 과적합을 나타내는 것은 아니며, 평평한 최솟값이 반드시 낮은 검증 오차를 나타내는 것은 아닙니다 [ML18]. 또한, 평평한 최솟값을 초래하는 함수는 검증 오차에 영향을 주지 않으면서 날카로운 최솟값을 초래하도록 변경될 수 있으며, 이는 위의 가설이 항상 성립하지 않음을 보여줍니다 [DPB+17].

일반화를 개선하기 위한 다양한 기술이 있으며, 종종 모델을 단순화(정규화)하는 방식입니다. 가장 일반적인 기술들은 다음과 같습니다:

**더 큰 데이터셋(Larger datasets)**은 과적합을 피하는 가장 좋은 기술입니다. 위의 장난감 예제는 4차 다항식을 훈련하기 위해 4개의 샘플만 사용했습니다. 동일한 모델 복잡성(4차 다항식)을 유지하면서 더 많은 샘플을 추가하면 훈련 세트에 없는 데이터에 더 잘 일반화되는 아핀(affine) 같은 함수가 됩니다. OpenAI는 NLP 모델의 경우 데이터셋이 두 배가 될 때마다 파라미터 수를 $2.55 \times$ 늘려 학습 능력을 향상시키고 과/과소 적합을 피할 것을 권장합니다 [KMH+20].

**가중치 감쇠(Weight decay)** (L2 정규화라고도 함)는 가중치의 크기에 페널티를 주어 과적합을 줄입니다. 위의 4차 다항식 예제에서 이는 계수의 크기에 페널티를 주어 더 아핀(affine) 같은 함수를 초래합니다. 목적 함수는 페널티 항을 추가하여 가중치 감쇠를 통합합니다.

$$J(w) = J_{data}(w) + \lambda ||w||^2$$

여기서 $\lambda \ge 0$은 정규화 계수이고 $w$는 모델 가중치(위의 회귀 예제에서 다항식 계수)입니다. 편향(bias) 가중치는 활성화와 곱셈 상호작용을 하지 않으므로 정규화되지 않습니다. 위에서 보여진 L2 정규화가 아닌 L1 정규화는 덜 일반적입니다.

**더 작은 배치(Smaller batches)**는 일반화를 향상시킵니다 [ML18]. 훈련 반복에는 데이터 배치를 처리하는 과정이 포함됩니다. 더 큰 배치는 계산상의 이점(데이터 재사용률이 높음)이 있을 수 있지만, 종종 큰 배치는 날카로운 최솟값을 초래합니다. 이상적인 것은 모델이 평평한 최솟값으로 수렴하고 높은 컴퓨팅 활용도를 갖는 중간 크기의 배치입니다. 적절한 배치 크기를 찾는 것은 실험이 필요합니다.

**더 나은 최적화기(Better optimizer)**는 더 낮은 검증 오차를 가진 솔루션을 찾습니다. 4.3절에서는 경사 하강법(gradient descent) 최적화기와 LARS, LAMB, RangerLARS와 같이 날카로운 최솟값 솔루션에 덜 민감한 다른 최적화기에 대해 논의합니다.

**토폴로지 가지치기(Topology pruning)**는 더 작은 가중치 중 일부를 강제로 0으로 만들거나 모델의 일부를 제거하는 것을 의미합니다. 6.3절에서 가지치기에 대해 더 자세히 논의합니다.

**레이블 스무딩 정규화(Label-smoothing regularization, LSR)**는 모든 0 항목에 작은 $\epsilon/M$ 값을 더하여 정답(ground-truth) 원-핫 벡터를 수정합니다. 여기서 $M$은 클래스의 수이고 $\epsilon$은 $\epsilon = 0.1$과 같은 작은 값입니다 [SVI+15]. 원-핫 벡터의 '1' 항목은 유효한 확률 분포를 유지하기 위해 $1 - \epsilon$으로 변경됩니다. 가장 큰 로짓(logit)과 다른 모든 로짓 간의 차이를 줄이면 모델의 확신(confidence)이 줄어들고 훈련되지 않은 샘플에 더 잘 적응하게 됩니다.

**조기 종료(Early stopping)**는 검증 오차가 증가하기 시작할 때 훈련을 중단하는 것을 의미합니다. 비슷하게, 모델은 $n$번의 훈련 반복마다 검증 데이터셋에서 평가되고 저장되며, 가장 낮은 검증 오차를 가진 모델이 선택됩니다. 조기 종료 사용에 대해서는 의견이 엇갈립니다. 조기 종료를 사용하지 않고 가중치 감쇠를 통한 정규화를 사용하는 것이, 여러 가중치 페널티를 실험할 수 있는 계산 리소스가 있을 때 더 나은 결과를 초래할 수 있습니다. 실제로 조기 종료는 과적합을 줄이는 간단하고 효과적인 기술이며 일반적으로 사용됩니다. 다소 관련하여, Hoffer 등은 검증 오차가 정체되었을 때 훈련 오차가 계속 감소하더라도 추가 훈련 주기를 통해 더 나은 일반화를 보여주었습니다 [HHS17].

**모델 앙상블(Model ensemble)**은 특정 작업에 대해 모델들의 앙상블(그룹)을 훈련시키는 것입니다. 추론 중에 모델 예측의 조합(예: 평균)이 사용됩니다. 예측을 결합하면 각 모델의 과적합 영향을 줄일 수 있습니다. 더 공식적으로, 모델 앙상블은 검증 오차의 분산을 줄입니다.

또한, 정규화(Normalization)와 드롭아웃(Dropout)(2.6절 및 2.9절에서 논의됨)은 과적합을 줄이는 다른 형태의 정규화(regularization)입니다.

## 4.2 가중치 초기화

모델 훈련은 특정 작업에 대한 토폴로지의 가중치 값을 학습하는 과정입니다. 훈련 시작 시 모델 가중치의 초기화는 학습(훈련 수렴)에 상당한 영향을 미칠 수 있으며, 특히 더 깊은 네트워크의 경우 더욱 그렇습니다.

모든 가중치를 동일한 값으로 초기화하면 가중치가 동일한 업데이트를 갖게 되어 학습을 방해합니다. 가중치(편향 포함)는 일반적으로 무작위 분포에서 샘플링됩니다. 이들은 활성화의 분포가 레이어 전체에 걸쳐 단위 분산(unit variance)을 갖도록 초기화됩니다. 이 초기화는 여러 레이어에 걸쳐 그래디언트를 곱할 때 역전파 단계에서 그래디언트 폭주(exploding) 또는 소실(diminishing)이 발생할 가능성을 줄입니다.

간단한 초기화 접근 방식은 영평균 정규(가우스) 분포 또는 레이어마다 다른 표준 편차를 사용하는 균등 분포에서 샘플링하는 것입니다. 활성화 함수가 ReLU일 때 일반적인 선택은 **Kaiming 초기화**입니다. 가중치는 표준 편차 $\sigma = \sqrt{2/D^{(l)}}$인 정규 분포에서 샘플링됩니다. 여기서 $D^{(l)}$은 레이어 $l$의 유닛 수입니다 [HZR+15]. 큰 크기의 가중치로 초기화되는 것을 방지하기 위해 절단된 정규 분포(분포의 양쪽 끝이 잘림)가 권장됩니다. Kaiming 초기화는 훨씬 더 깊은 네트워크의 훈련을 가능하게 합니다. 이 기술이 개발되기 전, 잘 알려진 VGG 논문의 저자들은 더 큰 VGG 네트워크의 레이어를 여러 단계에 걸쳐 꼼꼼하게 초기화했습니다. Kaiming 초기화를 사용하면 더 이상 그럴 필요가 없습니다.

시그모이드 또는 하이퍼볼릭 탄젠트 레이어의 경우 **Xavier 초기화**가 선호됩니다 [GB10]. 레이어 $l$의 가중치는 균등 분포 $U[-k, k]$에서 샘플링됩니다.

$$k = \sqrt{\frac{6}{D_{in} + D_{out}}}$$

이러한 초기화 기술은 기본 NN을 위한 가중치를 생성하는 메타-NN인 하이퍼네트워크를 훈련하도록 조정될 수 있습니다 [CFL20].

## 편향(Bias) 초기화

편향 가중치를 0으로 초기화하는 것이 일반적입니다. 예외는 다음과 같습니다:

- 불균형한 데이터셋(양성 샘플보다 음성 샘플이 훨씬 더 많음)으로 훈련된 이진 분류 모델의 마지막 레이어 편향은 다음과 같이 초기화해야 합니다 [Kar19].
  $$\log \frac{\text{양성 샘플 수}}{\text{음성 샘플 수}}$$
- 불균형한 데이터셋으로 훈련된 회귀 모델의 마지막 레이어 편향은 예상 평균 출력 값으로 초기화해야 합니다. 대안으로, 데이터 타겟을 정규화하고 편향을 0으로 초기화해야 합니다.
- LSTM 망각 게이트(forget gate)의 편향은 훈련 시작 시 LSTM 유닛이 망각하는 것을 방지하기 위해 1로 초기화해야 합니다. 모델은 망각하는 법을 배우기 위해 약간의 훈련 주기가 필요합니다 [GSC99, JZS15].
- LSTM 입력 및 출력 게이트의 편향은 초기 메모리 셀 활성화를 0으로 밀어 넣기 위해 -1로 초기화해야 합니다 [HS97].
- ReLU 레이어의 편향은 '죽은 ReLU(dying ReLU)' 현상을 유발할 수 있는 0 활성화의 수를 줄이기 위해 양수 값으로 초기화될 수 있습니다 [Ste19]. 그러나 그 이점은 광범위하게 탐구되지 않았습니다.

## 4.3 최적화 알고리즘: 비용 최소화

지도 학습 DL에서는 입력 데이터가 모델을 통해 순전파되고, 출력이 예상 출력(정답)과 비교되어 페널티 또는 비용을 계산합니다. 주어진 토폴로지와 데이터셋에 대해 비용(목적 함수) 지형(landscape), 즉 가능한 모든 가중치 값과 관련된 비용이 있습니다. 토폴로지 훈련의 목표는 낮은 비용을 갖는 가중치 세트(모델)를 찾는 것입니다.

최적화 알고리즘은 비용을 줄이기 위해 가중치를 반복적으로 업데이트합니다. 유용한 최적화기는 고차원 솔루션 공간을 효율적으로 탐색하고 낮은 비용의 평평한 최솟값으로 수렴합니다. DL에서 가중치(파라미터) 공간은 일반적으로 수백만에서 수천억 차원 범위이며, 계곡 바닥에 벽이나 장벽이 있는 대략적으로 볼록한 목적 함수를 가집니다 [XAT+18]. 계곡 바닥에는 여러 개의 국소 최솟값(local minima)이 있습니다. 주어진 토폴로지는 훈련의 확률성(stochasticity)으로 인해 훈련이 실행될 때마다 다른 국소 최솟값으로 수렴합니다. 흥미롭게도, 서로 다른 최솟값 솔루션은 일반적으로 비슷한 통계적 성능(비용)을 갖습니다.

프로덕션에서 가장 일반적인 최적화기는 모멘텀이 있는 확률적 경사 하강법(SGDM)과 Adam이며, 각각 컴퓨터 비전과 NLP 모델에 선호되는 경향이 있습니다. 이를 소개하기 전에, SGDM과 Adam의 유용성을 설명하기 위해 경사 하강법과 확률적 경사 하강법(SGD)을 먼저 소개합니다. 또한 대규모 배치의 사용을 이끈 LARS와 LAMB에 대해서도 논의합니다. 이러한 최적화기는 역전파 단계에서 계산된 그래디언트를 사용하여 모델 가중치를 업데이트합니다. 다음 섹션에서는 그래디언트를 계산하는 방법을 자세히 설명합니다. 아래 설명된 SWA 및 LookAhead와 같은 직교(orthogonal) 기술을 최적화기와 함께 사용하여 더 나은 최솟값을 찾을 수 있습니다.

**경사 하강법(Gradient Descent, GD)** 또는 최급 하강법(steepest descent)에서는 데이터셋의 모든 데이터 샘플을 사용하여 목적 함수를 계산합니다. 가중치는 그래디언트의 반대 방향, 즉 국소 최솟값을 향해 이동하여 업데이트됩니다. 목적 함수 $J(w)$는 $N$개의 샘플이 있는 데이터셋 전체의 손실 합을 사용하여 계산됩니다. 가중치 세트는 다음과 같이 업데이트됩니다:

$$w_{t+1} = w_t - \eta \nabla J(w_t)$$

$$\nabla J(w_t) = \frac{1}{N} \sum_{i=1}^N \nabla Loss(x_i, y_i, w_t)$$

여기서 $w$는 모델의 모든 가중치를 나타내고 $\eta$는 학습률(LR)입니다. 실제로는 가중치 감쇠 항(4.1절 참조)이 사용되지만, 표기를 단순화하기 위해 이 섹션의 모든 식에서 제외되었습니다.

LR은 그래디언트에 대한 반응으로 모델의 변화를 제어하며 수치적 안정성을 위해 조정해야 할 가장 중요한 하이퍼파라미터입니다 [Ben12]. 4.5.4절에서는 이 하이퍼파라미터와 다른 하이퍼파라미터를 조정하는 권장 사항을 제공합니다. 그림 4.5는 서로 다른 LR을 사용한 1D 공간에서의 GD 업데이트 장난감 예제를 보여줍니다. 높은 LR은 모델을 발산(diverge)시켜 비용을 감소시키는 대신 증가시킬 수 있습니다. 작은 LR은 수렴 단계 수와 훈련 시간이 필요 이상으로 길어질 수 있습니다. 적절한 LR은 최솟값(그림의 녹색 화살표)을 향한 적절한 진행을 초래합니다.

**SGD** 또는 더 정확하게는 **미니 배치 경사 하강법(Mini-batch Gradient Descent, MBGD)**에서는 데이터셋이 여러 배치로 나뉩니다. 통계 문헌에서 SGD는 배치 크기가 1인 MBGD를 의미하지만, 대부분의 DL 문헌과 이 책에서 SGD는 훈련 데이터셋보다 작은 임의의 배치 크기를 가진 MBGD를 의미합니다. 배치 크기가 전체 배치와 같으면 SGD는 GD가 되며, 1 에포크(epoch)는 1회의 훈련 반복과 같습니다. SGD에서 모델을 업데이트하는 데 사용되는 그래디언트는 그림 4.6과 같이 미니 배치에 대해 계산되며(전체 데이터셋이 아님), 그 외에는 SGD와 GD의 구현이 동일합니다.

GD와 대규모 배치 SGD에는 두 가지 주요 과제가 있습니다. 첫째, 각 단계 또는 반복은 많은 수의 샘플에 대해 비용을 계산해야 하므로 계산 비용이 많이 듭니다. 둘째, 최적화기는 그림 4.4 [ML18, YGL+18, DPG+14]와 같이 종종 일반화되지 않는 날카로운 최솟값 솔루션으로 수렴할 수 있습니다(이전 생각처럼 안장점(saddle point)에 갇히는 것이 아님).

그림 4.5: 너무 크거나(빨간색 화살표) 너무 작은 LR, 그리고 적절한(녹색 화살표) LR을 사용한 경사 하강법 업데이트.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000004_e7c90c48e435116ba2a943cc7706f7ac1212caa4e3e870d7181c68a4f3310081.png)

헤시안(1D에서는 2차 도함수)은 목적 함수의 곡률을 다양한 차원에 따라 분석하여 솔루션이 평평한 최솟값인지 날카로운 최솟값인지 확인하는 데 사용할 수 있습니다. 절대 고유값이 작을수록 해당 차원의 곡률이 더 평평함을 나타내며, 평균 헤시안 트레이스는 모든 차원의 평균 곡률에 대한 메트릭을 제공합니다. 트레이스 값이 높을수록 날카로운 최솟값을 나타냅니다 [DYC+19].

날카로운 최솟값으로 수렴하는 알고리즘적 이유는 잘 이해되지 않습니다. 한 가지 가설은 목적 함수에 많은 날카로운 최솟값이 있고 경사 하강법이 최적화 공간을 탐색하는 것이 아니라 시작 위치 바로 아래에 있는 국소 최솟값(일반적으로 날카로운 최솟값)으로 이동한다는 것입니다 [KMN+17]. 이 가설은 목적 함수가 대략적으로 볼록하다는 가설과 상충됩니다 [XAT+18]. 이유를 더 잘 이해하려면 추가 연구가 필요합니다.

배치 크기는 조정해야 할 중요한 하이퍼파라미터입니다. 배치 크기가 클수록 데이터 재사용이 많기 때문에 컴퓨팅 활용도가 높습니다. 즉, 더 큰 배치의 경우 데이터 읽기 대비 컴퓨팅 비율이 더 높습니다. 그러나 매우 큰 배치를 사용하면 GD와 동일한 문제가 발생하며 날카로운 최솟값으로 수렴하는 것을 피하기 위해 세심한 조정이 필요합니다. 여전히 마이크로 배치를 사용하는 것은 계산 리소스가 일반적으로 충분히 활용되지 않기 때문에 이상적이지 않습니다. 또한 마이크로 배치는 배치 정규화를 적절하게 사용할 수 있는 통계가 충분하지 않습니다 [Iof17]. 하드웨어 컴퓨팅 유닛을 효율적으로 사용할 만큼 충분히 크면서도 너무 많은 하이퍼파라미터 조정 없이 모델이 평평한 최솟값으로 적절하게 수렴할 만큼 충분히 작은 배치 크기의 최적 지점이 있습니다.

Shallue 등은 여러 모델과 데이터셋에 걸쳐 경험적으로 주어진 최적화기와 모델에 대해 세 가지 배치 크기 영역이 있음을 입증했습니다. 배치 크기와 LR이 비례하여 증가하고 훈련 반복 횟수가 비례하여 감소하는 **완벽한 확장(perfect scaling)** 영역이 있습니다. 배치 크기를 늘리면 반복 횟수가 줄어들지만 비례하지는 않는 **수확 체감(diminishing-returns)** 영역이 있습니다. 그리고 배치 크기를 늘려도 이점이 거의 또는 전혀 없는 **정체(stagnation)** 영역이 있습니다. 정체는 대규모 배치로 계산된 그래디언트의 분산이 낮기 때문에 발생합니다. 이는 이미 GD 그래디언트에 근접해 있으며 배치 크기를 더 늘려도 그래디언트가 크게 달라지지 않습니다. 또한 이미 논의했듯이 매우 큰 배치는 날카로운 최솟값으로 수렴할 수 있습니다. 그림 4.7은 널리 사용되는 세 가지 모델과 데이터셋에 대한 결과의 일부를 캡처하고 표 4.1은 결과를 요약합니다 [SLA+19]. 4.5.4절에서는 배치 크기 선택을 포함한 하이퍼파라미터 조정에 대해 논의합니다.

훈련 반복은 (평균적으로) 훈련 오차를 감소시켜야 합니다. 정체된 훈련 오차는 솔루션이 목적 함수의 가장자리를 따라 튕기고 있으며 더 이상

그림 4.6: 데이터셋이 M개의 배치로 나뉘고, 가중치 벡터(이 장난감 예제에서는 2차원)는 배치와 관련된 비용에 대해 계산된 그래디언트를 사용하여 업데이트됩니다. 최솟값(내부 타원)을 향한 진행은 매끄럽지는 않지만(GD와 달리) GD보다 빠릅니다. 1 GD 단계마다 SGD는 M 단계를 수행합니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000005_157f300c94655d09849fbb857b7735919a2321ea777dacec299c48c82ae5add0.png)

표 4.1: 그림 4.7에서 관찰된 세 가지 모델에 대한 배치 크기 확장 영역

| 모델 및 데이터셋     | 완벽한 확장 (Perfect)   | 수확 체감 (Diminishing)   | 정체 (Stagnation)   |
|-----------------------|-----------|---------------|--------------|
| Simple CNN on MNIST   | ≤ 128     | 128 - 2,048   | ≥ 2,048      |
| Transformer on LM1B   | ≤ 256     | 256 - 4,096     | ≥ 4,096      |
| ResNet-50 on ImageNet | ≤ 8,192   | 8,192 - 65,536  | ≥ 65,536     |

수렴하지 않음을 나타냅니다. LR을 줄이면 오차가 계속 감소하고 국소 최솟값에 더 가까운 솔루션으로 수렴하는 데 도움이 될 수 있습니다. 더 나은 접근 방식은 사용자가 설정한 높은 LR과 낮은 LR 사이의 **순환적 LR(cyclical LR)**을 사용하여 솔루션 공간을 더 잘 탐색하는 것입니다. 특히 훈련 후반부에 유용합니다 [LH17, Smi17, IPG+19]. 각 학습 주기는 높은 LR에서 시작하여 반복할 때마다 감소합니다. 낮은 LR에 도달한 후 또 다른 학습 주기가 시작됩니다(높은 LR에서). 이 기술은 모든 최적화기에 적용할 수 있습니다.

**SGDM**은 SGD 단독보다 수렴 속도를 향상시킵니다 [Qia99]. SGD라고 주장하는 문헌의 대부분의 훈련은 실제로는 SGDM을 사용했습니다. 즉, SGD라는 용어는 출판된 문헌에서 종종 SGDM의 별칭이지만, 혼란을 피하기 위해 이 장에서는 그렇지 않습니다. SGD 단독으로는 그림 4.8과 같이 **협곡(ravine)**(한 차원의 편미분이 다른 차원보다 훨씬 높은 영역)에서 진행 속도가 느립니다. 협곡은 DL 모델에서 흔한 수백만 차원에 걸친 최적화에서 널리 퍼져 있습니다.

SGDM은 **1차 모멘트(first moment)** 또는 그냥 **모멘트(moment)**라고도 하는 과거 그래디언트의 지수 붕괴 평균 방향으로 SGD를 가속화하고 진동을 완화합니다. 가중치를 직접 수정하는 대신 그래디언트는 이 모멘트를 수정하고 모멘트가 다음과 같이 가중치를 업데이트하는 데 사용됩니다.

$$m_t = \mu m_{t-1} + g_t$$
$$w_t = w_{t-1} - \eta m_t$$

여기서 $m$은 평균 그래디언트 또는 1차 모멘트이며 모멘텀 항 $\mu$(일반적으로 $\mu = 0.9$로 설정)에 의해 붕괴됩니다. $m$은 $m=0$으로 초기화되며 $\eta$는 조정이 필요한 LR입니다. SGDM은 업계, 특히 컴퓨터 비전 모델에서 널리 채택되었으며 학습률이 적절하게 조정되면 여러 작업에서 잘 작동합니다.

**Adaptive Moment Estimation (Adam)**은 모멘텀보다 다양한 LR에 더 강건하므로 LR 조정이 덜 필요합니다 [KB17]. Adam은 각 파라미터에 대해 적응형 LR을 계산합니다. 구체적으로, Adam은 **2차 모멘트(second moment)** 또는 **분산(variance)**이라고 하는 평균 그래디언트 제곱으로 정규화된 평균 그래디언트(SGDM과 같이)를 사용합니다. 따라서 모든 가중치는 다음과 같이 다른 LR로 업데이트됩니다.

$$m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t$$
$$v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2$$
$$\hat{m}_t = m_t / (1 - \beta_1^t)$$
$$\hat{v}_t = v_t / (1 - \beta_2^t)$$
$$w_t = w_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$

여기서 $m$과 $v$는 1차 및 2차 모멘트 추정치이고, $\hat{m}$과 $\hat{v}$는 각각 편향 보정된 1차 및 2차 모멘트 추정치입니다. $g^2$은 $g$의 요소별 제곱이고, 벡터 나눗셈은 요소별 나눗셈입니다. $m$과 $v$는 모두 0으로 초기화됩니다. $\beta_1 \in [0, 1)$, $\beta_2 \in [0, 1)$, $\epsilon > 0$은 일반적으로 $\beta_1 = 0.9$, $\beta_2 = 0.999$, $\epsilon = 0.001$로 설정됩니다. 지수 항 $t$는 훈련 반복이며 $\eta$는 약간의 조정이 필요한 LR입니다.

직관적으로 그래디언트의 분산이 작다는 것은 그래디언트가 비슷한 방향을 가리키고 있다는 것을 의미하며, 이는 방향이 옳다는 확신을 증가시킵니다. 따라서 더 큰 LR을 사용하여 해당 방향으로 더 큰 단계를 밟습니다. 분산이 클 때는 반대 현상이 발생합니다. 작은 단계를 밟습니다.

SGD에서 Adam으로 전환할 때 Adam은 더 많은 정규화가 필요하므로 정규화 하이퍼파라미터를 조정해야 합니다 [LH19]. 원래 논문에서는 $\epsilon = 10^{-8}$을 사용했지만, 훈련 후반부에 자주 발생하는 $\hat{v}$가 매우 작을 때 거대한 단계 크기를 방지하기 위해 $\epsilon = 10^{-3}$을 권장합니다 [KB17].

Adam은 업계, 특히 NLP 모델에서 널리 채택되었으며 더 간단한 볼록 최적화 작업에서 최적의 솔루션으로 수렴하지 않음에도 불구하고 여러 작업에서 경험적으로 잘 작동합니다 [RKK19]. SGDM은 LR이 잘 조정되었을 때 새로운 기술에 비해 다양한 작업에서 여전히 잘 작동하거나 더 나은 성능을 보입니다. SGDM은 종종 Adam보다 훈련 시간은 더 길지만 더 잘 수렴하고 일반화됩니다 [WRS+18, KS17]. 일부 실무자들은 수렴 속도 때문에 Adam으로 훈련을 시작하고 수렴 품질 때문에 SGDM으로 마무리합니다.

**Rectified Adam (RAdam)**은 Adam과 SGDM 사이를 전환하는 Adam의 간단한 적응입니다 [LJH+19]. RAdam은 분산 신뢰도에 따라 적응형 LR을 동적으로 켜거나 끕니다. 따라서 분산을 계산하는 데 사용되는 제한된 데이터 포인트로 인한 Adam의 초기 훈련 불안정성은 이 온/오프 적응형 LR로 완화됩니다. RAdam은 분산에 대한 확신을 얻으면 수정된(rectified) 적응형 LR을 사용합니다. 그렇지 않으면 SGDM으로 돌아갑니다.

위의 모든 최적화기는 LARS와 LAMB가 해결하는 공통적인 과제를 공유합니다. 안정성을 유지하기 위해 크기가 작은 가중치는 가중치 업데이트 크기도 작아야 하며, 그 반대도 마찬가지입니다. 그러나 모델의 모든 레이어는 종종 매우 다른 $||w^{(l)}|| / ||g^{(l)}||$ 비율을 갖습니다. 비율이 작으면 훈련 불안정(발산)이 발생할 수 있고, 비율이 크면 학습 속도가 느려질 수 있습니다. LARS와 LAMB는 각 레이어의 단계 크기를 정규화하여 훈련 안정성을 향상시킵니다. 이러한 추가적인 안정성은 대규모 배치(실험적으로 결정된 크기까지)로 훈련할 수 있게 합니다.

**Layer-wise Adaptive Rate Scaling (LARS)**은 가중치의 크기와 그래디언트의 크기 비율에 비례하는 국소 LR $\eta^{(l)}$ 을 사용합니다 [YGG17]. LARS는 다음과 같이 SGD에 적용됩니다.

$$\eta^{(l)} = \eta_0 \times \frac{||w^{(l)}||}{||g^{(l)}|| + \lambda ||w^{(l)}||}$$

여기서 $\eta_0$는 글로벌 LR입니다.

LARS는 SGDM 또는 **LAMB**라고 알려진 Adam과 함께 사용할 수 있습니다 [YLR+20]. LAMB는 Google에서 거의 하이퍼파라미터 조정 없이 배치 크기 32K로 BERT와 ResNet-50을 훈련하는 데 성공적으로 사용되었습니다. LAMB에서 Adam 방정식은 다음과 같이 수정됩니다.

$$w_t^{(l)} = w_{t-1}^{(l)} - \eta_t \frac{\phi(||w_{t-1}^{(l)}||)}{||r_t^{(l)}|| + \lambda ||w_{t-1}^{(l)}||} (m_t^{(l)} / \sqrt{v_t^{(l)}})$$

다른 영향력 있는 최적화기로는 AdaGrad(특히 희소 데이터용), RMSProp, AdaDelta, Nadam, Nesterov 가속 그래디언트(NAG), AdamW, AMSGrad, NovoGrad가 있습니다 [DHS11, HSS12, Zei12, Doz16, BLB17, LH19, RKK19, GCH+20]. 그림 4.9는 최적화기의 추정 계보를 보여줍니다. 이들은 1차(first-order) 최적화기입니다. **AdaHessian**은 다른 2차 최적화기의 엄청난 계산 비용 없이 1차 최적화기보다 더 나은 최솟값으로 수렴하는 2차(second-order) 최적화기입니다 [YGS+20]. 유망한 결과를 감안할 때 AdaHessian 채택이 증가할 수 있습니다.

**Stochastic Weight Averaging (SWA)**와 **LookAhead (LA)**는 더 나은(더 평평한) 최솟값으로 수렴하여 일반화를 개선하는 상호 보완적인 기술입니다 [IPG+19, ZLH+19]. SWA의 동기는 훈련 반복 후반부 동안 SGD가 더 넓은 최솟값의 경계 사이에서 튀어 오른다는 것입니다. 튀어 오르는 것들의 평균은 더 나은 솔루션입니다. SWA는 최적화기가 사용하는 일반 가중치 세트 $w$ 외에도 별도의 평균 가중치 세트 $w_{SWA}$를 유지합니다. $w_{SWA}$ 는 훈련 반복의 최소 75%를 완료한 후 $w$ 로 초기화됩니다. 그런 다음 여러 번의 반복을 완료한 후 $w_{SWA}$ 는 다음과 같이 업데이트됩니다.

$$w_{SWA} = \frac{w_{SWA} \cdot n_{cycle} + w}{n_{cycle} + 1}$$

여기서 $n_{cycle}$은 $w_{SWA}$ 초기화 후 완료된 사이클 수이고 $w$ 는 최적화기가 학습한 모델입니다. 한 사이클은 여러 반복(일반적으로 1 에포크)으로 구성되지만 데이터셋 크기에 따라 달라질 수 있습니다.

훈련을 위해 SWA는 $sizeof(w_{SWA})$ 만큼의 추가 메모리가 필요하며, 이는 활성화에 비해 상대적으로 작고 업데이트하는 데 무시할 수 있는 추가 계산이 필요합니다. 서빙(serving)에는 추가 메모리나 계산이 필요하지 않습니다.

**LookAhead (LA)**는 SWA와 유사한 접근 방식을 따릅니다 [ZLH+19]. 주요 차이점은 최적화기가 몇 번의 반복 후에 가중치를 $w_{LA}$ 로 업데이트한다는 것입니다: $w \leftarrow w_{LA}$. 즉, 이동 평균 $w_{LA}$ 가 최적화 궤적을 변경합니다.

**Ranger**는 RAdam과 LA의 조합이며, **RangerLARS**는 Ranger에 LARS 기술을 적용합니다 [Wri19]. 우리는 Ranger를 기본 최적화기로, 대규모 배치를 사용할 때 RangerLARS를 사용할 것을 권장합니다.

## 4.4 역전파 (BACKPROPAGATION)

1980년대 역전파 알고리즘의 재발견은 다층 신경망(NN) 훈련을 촉진했습니다. 역전파는 최적화 알고리즘에서 사용되는 그래디언트를 계산하는 효율적인 방법을 제공합니다. 이 섹션에서는 학습 과정을 명확히 하기 위해 역전파 뒤에 있는 수학의 일부를 소개합니다. 이러한 모든 세부 사항에 관심이 없는 독자의 경우, 역전파가 결국 곱셈과 덧셈으로 귀결된다는 점만 기억하면 됩니다.

로그 비용(log-cost) 또는 로지스틱 비용(logistic cost)이라고도 하는 교차 엔트로피(cross-entropy) 비용 함수는 다음과 같습니다.

$$J(w) = - \sum_{n=1}^N \sum_{k=1}^K y_k^{(n)} \log(\hat{y}_k^{(n)})$$

여기서 $N$은 훈련 배치의 샘플 수이고, $y_k^{(n)} \in \{0, 1\}$은 샘플 $n$이 클래스 $k$에 속하면 1이고 그렇지 않으면 0입니다. $\hat{y}_k^{(n)}$은 샘플 $n$이 클래스 $k$에 속할 것이라는 모델의 예측(확률로서)입니다. 직관적으로 모델이 올바른 클래스에 대해 낮은 확률을 예측하면 해당 샘플에 대한 비용이 높고 그 반대의 경우도 마찬가지입니다. $y_k^{(n)}=1$일 때 $\hat{y}_k^{(n)}$이 0에 가까워지면 손실은 무한대에 가까워집니다. 실제로는 비용 함수에 가중치 감쇠 페널티가 포함됩니다(여기서는 표기를 단순화하기 위해 종종 생략됨).

$$J(w) = -\sum_{n} \sum_{k} y_k^{(n)} \log(\hat{y}_k^{(n)}) + \lambda ||w||^2$$

여기서 $\lambda \ge 0$은 정규화 계수입니다.

이 목적 함수는 데이터 과학자가 선택한 4.3절의 최적화기를 사용하여 최소화됩니다. 최적화기에 대한 입력은 각 가중치 $w_{ji}^{(l)}$에 대한 비용의 그래디언트 또는 편미분입니다.

$$\frac{\partial J(w)}{\partial w_{ji}^{(l)}}$$

이는 레이어의 모든 가중치와 토폴로지의 모든 레이어에 대해 계산되어야 합니다. 각 편미분은 해당 가중치의 변화가 비용을 어떻게 변화시키는지를 나타내는 지표입니다. 최적화기는 비용을 줄이기 위해 각 가중치를 어떻게 조정할지 지정합니다.

그림 4.10은 토이 모델에서 역전파가 하나의 편미분, 구체적으로 $\frac{\partial L}{\partial w_{32}^{(0)}}$를 계산하기 위해 어떻게 작동하는지 보여줍니다. 여기서 표기를 단순화하기 위해 $L = J(w)$입니다. 이 편미분은 다음 레이어의 그래디언트에 의존하고, 이는 그 다음 레이어의 그래디언트에 의존하며 계속 이어집니다. 색상 상자의 편미분은 순전파 방정식에서 계산되며, 그 수치 값은 방정식 체인에 대입되어 $\frac{\partial L}{\partial w_{32}^{(0)}}$를 결정할 수 있습니다. 은닉층은 ReLU 활성화 함수를 가정합니다. 실제로 전체 레이어에 대한 편미분은 행렬 대수를 사용하여 그룹으로 계산됩니다.

그림 4.7: 그림 4.7의 세 가지 모델에 대해 예상되는 훈련 및 검증 오차를 충족하는 데 필요한 훈련 단계 수(배치 크기 함수로서). 점선은 완벽한 확장을 나타냄. 표 4.1에서 요약 내용 참조. 출처: [SLA+19] (CC BY-SA 4.0).

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000006_bc94571011cb4920397e39a39fcb5ad52bb0c373b851e663b28449fd67464b16.png)

그림 4.8: 협곡이 있는 2D 공간의 장난감 예제. (a) SGD는 느리게 진행됩니다. (b) SGDM은 최솟값을 향해 더 빠르게 진행됩니다. [Orr99]에 기초함.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000007_41311c7e65cc9c5fac5014622498fbff4b46239ae2c2aab02e1c6cdc3a405e76.png)

그림 4.9: 최적화 알고리즘의 계보.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000008_1712f1c370e7c56c80f36ee2bb08541fd7948569f92dae618ea02b98b59c265f.png)

그림 4.10: 연쇄 법칙(chain rule)을 사용하여 모델의 가중치에 대한 비용의 편미분을 계산합니다. 간단하게 하기 위해 편향은 그림에서 생략되었습니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000009_f938906172bbe8404baaab063bf43a259a134a0cabd759445ff7ca43e5eedf5f.png)

## 4.5 훈련 기술

모델 훈련에는 데이터셋 준비와 토폴로지 선택, 최적화기 선택, 배치 크기 지정과 같은 다양한 하이퍼파라미터 조정이 포함됩니다. 이 섹션에서는 데이터셋 준비, 토폴로지 설계, 훈련 디버깅에 대한 일반적인 지침을 설명합니다. 이러한 지침은 폐쇄형 최적 솔루션(closed-form optimal solution)보다는 현재 가장 좋은 경험적 방법(heuristics)을 기반으로 합니다. 따라서 지침이 특정 훈련 작업에 유익한지 확인하기 위해 실험이 필요할 수 있습니다.

## 4.5.1 훈련 데이터셋

훈련의 첫 번째 단계는 데이터셋의 샘플을 수동으로 분석하여 샘플(또는 대부분)이 손상되지 않았는지, 중복이 없는지, 적절한 레이블이 있는지 확인하고 클래스 불균형을 식별하는 것입니다. 클래스 불균형은 훈련 샘플이 클래스 간에 고르게 분포되지 않았음을 의미합니다. 예를 들어, 방사선 이미지를 사용하여 종양 분류기를 훈련하는 데 사용되는 데이터셋은 종양이 있는 이미지보다 종양이 없는 이미지가 더 많을 가능성이 큽니다. 간단한 접근 방식은 다른 곳에서 논의된 SMOTE 또는 ADASYN과 같은 기술을 사용하여 과소평가된 클래스를 오버샘플링(oversample)하거나 인위적으로 샘플을 늘리고 [CBH+11, HBG+08], 생성된 샘플이 현실적인지 확인하기 위해 항상 분석하는 것입니다. 또 다른 접근 방식은 분류하기 더 어려운 샘플을 유지하면서 과대평가된 클래스를 언더샘플링(undersample)하는 것입니다. 분류하기 더 어려운 샘플을 선택하는 한 가지 접근 방식은 과대평가된 클래스의 부분 집합으로 여러 모델을 훈련하고 잘못 분류된 샘플을 선택하는 것입니다. 클래스 불균형을 다루는 것은 열린 연구 분야입니다. 분류기가 항상 오버샘플링된 클래스를 예측하는 정확도 역설(accuracy paradox)에 빠지는 것을 피하기 위해 불균형 데이터셋 작업에는 분류율(classification rate)보다 F1 점수와 같은 메트릭을 사용하는 것이 좋습니다. 또한 4.2절에서 클래스 불균형이 마지막 레이어의 편향 초기화에 영향을 미친다는 점을 상기하십시오.

훈련 데이터셋은 훈련 세트, 검증 세트(out-of-sample 또는 development set라고도 함), 테스트 세트로 분할되어야 합니다. 훈련 세트는 모델을 훈련하는 데 사용되며, 검증 세트는 훈련 세트 외부의 데이터에 대한 모델의 통계적 성능을 관찰하는 데 사용됩니다. 하이퍼파라미터는 검증 세트의 성능을 기반으로 조정됩니다. 테스트 세트는 모델과 하이퍼파라미터가 확정된 후, 모델을 훈련하거나 조정하는 데 사용되지 않은 데이터에 대해 배포 시 성능을 추정하기 위해 단 한 번만 사용해야 합니다. 훈련-검증-테스트 백분율 분할은 전체 훈련 데이터셋의 크기와 훈련 및 배포 데이터 간의 유사성에 따라 다릅니다. 모든 훈련 샘플이 동일한 분포에서 왔다고 가정할 때, 10,000개 샘플이 있는 데이터셋의 적절한 백분율 분할은 80-15-5, 100만 개 샘플이 있는 데이터셋은 95-4-1, 1억 개 샘플이 있는 데이터셋은 99.0-0.9-0.1입니다. 검증 및 테스트 세트는 서빙 데이터와 동일한 분포에서 샘플링해야 합니다. 즉, 모델 파라미터를 적절하게 조정하려면 프로덕션에서 사용되는 데이터와 최대한 유사해야 합니다. 오버샘플링은 훈련 데이터셋을 분할한 후에 수행해야 데이터 샘플이 훈련 및 검증 세트 모두에 존재하는 것을 방지할 수 있습니다.

훈련 세트 전처리에는 일반적으로 평균을 빼고 분산을 정규화하는 과정이 포함됩니다. 훈련 세트에 사용된 통계 및 기술이 검증 세트 및 배포 시에도 동일하게 사용되는 것이 중요합니다. 특히 훈련 샘플에서 훈련 세트의 평균을 뺀 경우, 검증 세트 및 배포 시에도 동일한 훈련 평균값을 빼야 합니다. 서로 다른 팀이 모델을 훈련하고 배포할 때 배포 데이터에서 전처리 훈련 단계를 미러링하는 것을 무시하여 예상보다 낮은 성능을 초래하는 경우가 있습니다.

데이터 증강(Data augmentation)은 컴퓨터 비전, 음성 인식 및 언어 처리 작업에서 데이터셋 크기를 늘리는 일반적인 기술입니다. 음성 인식에서 각 샘플은 시간 및 주파수 마스킹과 시간 워핑을 통해 시간 및 주파수 도메인에서 샘플을 마스킹하거나 수정하여 증강될 수 있습니다 [PCZ+19]. 컴퓨터 비전에서 각 샘플은 좌우 반전, 다양한 위치에서의 자르기(crop), 약간의 회전이 가능합니다. 각 샘플을 10배 증강하여 인위적으로 데이터셋을 한 자릿수(order of magnitude)만큼 늘리는 것이 일반적입니다. 언어 처리에서 문장은 문장의 일부 단어의 동의어를 사용하여 데이터셋을 증강하기 위해 복제될 수 있습니다.

훈련 세트를 준비하는 마지막 단계는 레이블과의 연관성을 깨지 않고 순서를 섞는 것(shuffle)이며, 모든 전처리 단계 후 증강된 샘플 중 일부를 수동으로 재분석하여 여전히 유효한지 확인하는 것입니다. 각 에포크 사이에 훈련 데이터를 다시 섞는 것은 일반적으로 도움이 되지 않습니다.

## 4.5.2 토폴로지 설계

특정 작업을 위한 토폴로지를 설계하는 권장 접근 방식은 간단한 토폴로지로 시작한 다음 복잡성을 추가하는 것입니다. 일부 작업의 경우 훨씬 적은 컴퓨팅이 필요한 선형 회귀나 XGBoost(이 알고리즘에 익숙하지 않아도 걱정하지 마십시오)와 같은 다른 ML 알고리즘으로 충분할 수 있습니다.

설계 단계에서 fp32와 비교적 작은 배치 크기를 사용하면 발생하는 문제가 작은 수치 표현이나 큰 배치 크기와 관련이 없음을 확인할 수 있습니다. 업계가 bf16의 견고성에 대해 더 많은 확신을 얻음에 따라 설계 단계가 bf16으로 이동할 수 있습니다. 복잡성을 높이기 전에 설계자는 모델이 다음을 올바르게 수행하는지 확인해야 합니다.

1. 데이터를 소비한다.
2. 유효한 출력을 생성한다.
3. 예상 비용을 생성한다.
4. 무작위 또는 모두 0인 데이터 대 실제 데이터로 훈련할 때 더 나은 모델을 학습한다.
5. 예를 들어 두 개의 샘플과 같은 아주 작은 데이터셋으로 훈련할 때 과적합된다.

그런 다음 설계자는 더 많은 유닛과 레이어로 복잡성을 점진적으로 늘리며 매번 정확성을 다시 확인해야 합니다. 몇 개의 데이터 샘플에 과적합할 수 없는(훈련 오차가 0에 가깝거나 같지 않음) 토폴로지 및 훈련 과정은 버그를 나타낼 가능성이 높습니다.

4.5.3절에서는 모델이 예상대로 작동하지 않을 때의 디버깅 단계를 자세히 설명합니다. 데이터 과학자는 훈련 과정 전체에서 훈련 및 검증 오차를 모니터링해야 합니다. 토폴로지에 더 많은 레이어와 유닛을 추가함에 따라 훈련 오차가 감소해야 합니다. 그렇지 않으면 버그를 나타낼 수 있습니다. 이 '단계별 검증(verification-at-every-step)' 접근 방식은 디버깅하기 어려운 문제로 가득 찬 크고 복잡한 토폴로지를 갖는 것을 방지합니다. 더 작은 토폴로지에서 문제를 찾아 해결하는 것이 훨씬 쉽습니다. 배치 정규화(Batch Normalization) 레이어를 도입하려면 배치 크기를 약 32로 늘려야 합니다. 배치 정규화는 아주 작은 배치에서는 잘 작동하지 않기 때문입니다. 더 나은 접근 방식은 그룹 정규화(2.6절 참조) 또는 마이크로 배치를 사용할 수 있는 다른 정규화 기술을 사용하는 것입니다.

한 가지 실용적인 접근 방식은 관련 작업 및 데이터셋 크기용으로 설계된 기존 토폴로지(참조 구현)를 향해 레이어별로 토폴로지를 구축하는 것입니다. 4.5.4절에 자세히 설명된 대안적 접근 방식은 기존 토폴로지로 시작하여 필요한 작업에 맞게 조정하고 하이퍼파라미터를 조정하는 것입니다. 어느 접근 방식이든 토폴로지의 깊이와 크기는 데이터셋의 크기에 따라 달라집니다. 두 접근 방식 모두 모델이 예상대로 작동하지 않을 때 4.5.3절에 설명된 디버깅 단계에 따라 단계별 검증이 성공적인 설계에 필수적입니다.

또 다른 권장 사항은 훈련 데이터셋에 과적합되는 더 깊은 모델을 점진적으로 구축한 다음 가중치 감쇠와 같은 정규화 기술을 사용하여 과적합을 줄이는 것입니다. 이 과정에서 데이터 과학자는 훈련 및 검증 오차를 면밀히 모니터링하고 검증 오차를 줄이기 위해 토폴로지를 수정합니다. 높은 훈련 오차는 더 큰 토폴로지가 필요함을 나타냅니다. 높은 검증 오차는 정규화 또는 더 큰 훈련 데이터셋이 필요함을 나타냅니다. 또한 메모리 크기와 같은 서빙 하드웨어의 제약 조건이 설계 프로세스에 포함되어야 합니다.

정규화 전의 과적합은 두 가지 목적을 갖습니다. 첫째, 모델이 데이터셋의 복잡성을 포착할 만큼 충분히 크다는 것을 나타냅니다. 둘째, 훈련 과정이 올바르게 작동하고 있음을 검증하는 방법입니다. 데이터 증강은 최종 설계 단계를 위해 예약된 정규화의 한 형태입니다.

설계 단계에서는 (감쇠하는 LR이 아닌) 상수 LR과 Adam 최적화기를 사용하는 것이 좋습니다. RangerLARS와 같은 고급 최적화기 및 순환 LR과 같은 고급 LR 기술은 토폴로지 설계가 완료된 후 탐색해야 합니다. 더 깊은 모델은 일반적으로 더 큰 LR이 필요하므로 설계 단계의 모든 단계에서 새로운 LR을 찾아야 할 수도 있습니다.

## 4.5.3 훈련 디버깅

훈련 디버깅은 매우 어려울 수 있습니다. 데이터 처리 및 토폴로지 정의부터 최적화기 및 수치 표현에 이르기까지 훈련 파이프라인의 여러 부분에 오류 소스가 있습니다 [Kar19]. 다음 단계는 모델이 예상대로 훈련되지 않을 때 버그를 확인하고 수정하는 데 도움이 될 수 있습니다.

1. 더 작은 수치 표현이 오류의 원인이 아님을 확인하기 위해 fp32를 사용하십시오.
2. 모든 전처리 단계 후 샘플을 시각화하여 불합리한 왜곡이 도입되지 않았는지 확인하십시오.
3. 검증 데이터셋이 텐서 레이아웃을 포함하여 훈련 세트와 동일한 통계 및 기술을 사용하여 전처리되는지 확인하십시오.
4. 드롭아웃과 정규화 레이어가 동시에 사용되지 않는지 확인하십시오. 그렇다면 드롭아웃 레이어를 영구적으로 제거하십시오.
5. 작은 배치 크기로 훈련하십시오. 배치 정규화 레이어가 있는 경우 배치 크기를 약 32로 사용하거나 배치 정규화를 그룹 재정규화로 교체하는 것이 좋습니다.
6. Tensorboard와 같은 시각화 도구로 각 레이어의 활성화 출력을 시각화하여 타당한지 확인하십시오. 예를 들어 CNN 모델의 첫 번째 레이어는 일반적으로 에지를 감지하는 법을 배웁니다.
7. 모델이 훈련 샘플에 빠르게 과적합될 수 있는지 확인하기 위해 훈련 샘플 수를 일시적으로 두 개의 샘플로 줄이십시오.
8. 초기 비용이 직관과 일치하는지 확인하십시오. 예를 들어 균형 잡힌 데이터셋을 사용한 0~9 숫자 분류는 크기 N의 배치에 대해 약 $-\ln(1/10) \times N \approx 2.3N$의 초기 비용을 가져야 합니다.
9. 일반 훈련 데이터가 무작위 또는 제로 입력 훈련 데이터보다 더 높은 통계적 성능을 가져오는지 확인하십시오. 그렇지 않다면 모델이 데이터를 손상시키거나 무시하고 있음을 나타냅니다.
10. 잘못 예측된 샘플을 시각화하고 패턴을 찾으십시오.
11. 코드에서 버그를 찾을 때 정확히 동일한 동작을 재현하기 위해 고정된 랜덤 시드를 사용하고, 관찰된 동작이 예상 동작과 다른 곳을 찾기 위해 레이어별로, 연산(op)별로 디버깅하십시오.
12. 다양한 가중치 감쇠 페널티로 실험하고 훈련 동작이 예상대로 변경되는지 관찰하십시오. 더 많은 정규화(더 높은 페널티)는 모델이 과적합되는 경우 훈련 오차를 증가시키고 테스트 오차를 감소시켜야 합니다.
13. 상수 LR과 순환 LR을 모두 사용하여 다양한 LR로 실험하고, 반복 횟수 대 훈련 및 검증 오차를 플로팅하여 오차의 동작이 예상대로인지 관찰하십시오.
14. 많은 그래디언트 값이 0이 되어 적절한 학습을 방해하는 경우 ReLU를 LeakyReLU로 교체하십시오.
15. 출력이 엄격하게 0과 1 사이일 필요가 없다면 모든 시그모이드 함수를 하이퍼볼릭 탄젠트 함수로 교체하십시오. 시그모이드 함수는 LSTM 게이트의 확률을 나타내거나 이진 분류 모델의 마지막 레이어로 제한하십시오.
16. 높은 그래디언트 값을 클리핑(clip)하십시오.
17. 정규화가 찾기 어려운 버그를 가리고 있지 않은지 확인하기 위해 정규화 레이어를 일시적으로 제거하십시오.
18. 올바른 API가 사용되는지 확인하십시오. 예를 들어 음의 로그 우도 손실(negative log-likelihood loss)과 교차 엔트로피 손실이 때때로 잘못 상호 교환됩니다.

## 4.5.4 하이퍼파라미터 조정

이 섹션에서는 LR, 배치 크기, 가중치 감쇠, 최적화기와 같은 하이퍼파라미터 조정에 대한 권장 사항을 제공합니다. 또한 하나의 하이퍼파라미터가 다른 하이퍼파라미터에 어떤 영향을 미칠 수 있는지 설명합니다. 모든 권장 하이퍼파라미터는 적절한 조정을 위해 실험이 필요합니다. 일반적으로 여러 번의 훈련 반복 후 좋은 하이퍼파라미터 세트는 추가 훈련 반복으로 더 좁힐 수 있는 몇 가지로 좁혀집니다. 즉, 모든 하이퍼파라미터로 전체 훈련을 하는 것은 필요하지 않으며 실용적이지도 않습니다.

LR은 조정해야 할 가장 중요한 하이퍼파라미터입니다 [Ben12]. 다음을 포함하여 훈련 과정 전반에 걸쳐 LR을 조정하는 다양한 기술이 있습니다.

- **상수(Constant)**: 모든 반복에 동일한 LR을 사용합니다.
- **단계적 감소(Stepwise decreasing)**: 정해진 수의 에포크 후에 LR을 반복적으로 줄입니다.
- **다항식 감쇠(Polynomial decay)**: 각 반복마다 LR을 약간 줄입니다.
- **순환(Cyclical)**: LR을 반복적으로 줄였다가 늘립니다.
- **순환적 감소(Cyclically decreasing)**: 일부 반복 동안 LR을 반복적으로 줄였다가 재설정합니다.

새로운 토폴로지를 훈련할 때의 목표는 낮은 검증 오차를 달성하는 것입니다. 새로운 토폴로지를 훈련하는 권장 접근 방식은 다음과 같습니다. (1) 비교적 작은 배치 크기를 사용합니다 (배치 정규화 레이어가 있는 경우 배치 크기 32를 사용하거나 BN을 그룹 정규화로 교체). (2) $10^{\{-5.0, -4.5, \dots, 0.0\}}$과 같은 다양한 초기 LR을 테스트하고 훈련 오차를 발산시키지 않는 충분히 큰 LR을 선택합니다 [ML18]. (3) 훈련 및 검증 오차가 모두 평평해질 때까지 모델을 훈련합니다 [HHS17]. (4) LR을 10배 줄이고 LR을 줄여도 오차가 더 이상 줄어들지 않을 때까지 단계 (3)을 여러 번 반복합니다. 선택적으로 훈련의 마지막 부분에서는 LR이 감소했다가 다시 증가하는 순환 LR로 전환합니다.

알려진 검증 오차를 가진 확립된 토폴로지를 훈련할 때의 목표는 훈련 시간을 줄이는 것입니다. 권장 사항은 배치 크기 완벽 확장 영역(표 4.1 참조)에서 가장 큰 배치 크기를 사용하는 것입니다. 이 배치 크기의 추정치는 각 그래디언트 성분의 분산 합계를 그래디언트의 글로벌 노름(norm)으로 나눈 값입니다. 직관적으로 마이크로 배치로 계산된 그래디언트는 분산이 높고 그 반대의 경우도 마찬가지입니다. 따라서 좋은 배치 크기는 그래디언트 자체와 동일한 규모의 그래디언트 분산을 초래합니다 [MKA+18].

또한 초기 점진적 웜업(warmup) 단계가 권장됩니다. 목표 초기 LR이 $\eta_0$인 경우 최적화기는 먼저 $\eta_0/20$의 LR을 사용하고 $\eta_0$에 도달할 때까지 처음 약 10% 에포크 동안 이 LR을 선형적으로 증가시켜야 합니다. 그런 다음 최적화기는 처방된 LR 훈련 기술을 계속해야 합니다. 웜업 단계의 동기는 훈련이 작은 LR로 바로 수렴하기 시작하도록 돕고, 그런 다음 LR을 증가시켜 더 빠른 진전을 이루는 것입니다.

확립된 모델의 경우 다항식 감쇠 LR이 일반적으로 처방되는 LR 기술입니다.

$$\eta_t = \eta_0 (1 - t/T)^p$$

여기서 $\eta_0$는 초기 LR, $t$는 현재 반복, $T$는 총 반복 횟수입니다. 마지막으로 훈련 에포크의 마지막 약 20%에 순환 LR을 적용하면 도움이 될 수 있습니다.

권장 최적화기는 대규모 배치의 경우 RangerLARS(LARS + RAdam + LookAhead)이고 중소 규모 배치의 경우 더 단순한 Ranger(RAdam + LookAhead)입니다 [Wri19].

또 다른 핵심 하이퍼파라미터는 L2 정규화 또는 가중치 감쇠 $\lambda$입니다. 시도해 볼 권장 값은 $\lambda = 10^{\{-6, -5, -4, -3\}}$입니다. 모델이 과적합될수록 정규화가 더 필요합니다. 또한 4.3절의 최적화 알고리즘에 사용되는 $\beta$와 같은 다른 파라미터도 약간의 조정이 필요할 수 있습니다 [Smi17]. 데이터 증강, 축소된 수치 표현(6.1절 상세), 가중치 가지치기(6.3절 상세), 더 큰 LR과 같은 기술은 정규화에 기여합니다. 이러한 기술을 사용하면 필요한 가중치 감쇠 값을 줄일 수 있습니다. AutoML 기술(10.1절 소개)도 하이퍼파라미터 조정에 사용할 수 있습니다.

## 4.6 미세 조정(FINE-TUNING)을 통한 전이 학습

미세 조정을 통한 전이 학습(Transfer learning)은 많은 산업 전반에 걸쳐 광범위하게 채택되고 있습니다. 아이디어는 특정 소스(source) 작업에서 얻은 지식을 다른 대상(destination) 작업에 사용하는 것입니다. 예를 들어, 서로 다른 이미지는 가장자리(edge)부터 시작하여 복잡성이 증가하는 공통적인 특징을 가지고 있습니다. 모델은 대규모 이미지 데이터셋에서 훈련된 다음, 모델의 상위 레이어만 교체하고 미세 조정(재훈련)하여 더 작은 데이터셋을 가진 다른 작업에 사용할 수 있습니다. 두 작업 모두 동일한 하위 수준 특징을 사용할 수 있습니다. 전체 모델은 교체되지 않은 레이어에 대해 사전 훈련된 가중치를 초기 가중치로 사용하고, 교체된 레이어는 전통적인 가중치 초기화 기술(4.2절에서 논의됨)을 사용합니다.

대부분의 회사는 하이퍼스케일러에 비해 작은 데이터셋을 가지고 있습니다. 다행히도 커뮤니티를 위해 대규모 데이터셋으로 훈련된 모델이 있는 모델 동물원(model zoos)이 있습니다. 데이터셋이 작은 산업계와 학계는 이러한 사전 훈련된 모델을 사용하여 관련 작업에 맞게 미세 조정할 수 있습니다. 기존 모델을 미세 조정하면 대규모 모델 훈련의 장벽이 획기적으로 낮아지고 DL 채택이 급격히 증가합니다.

다음은 미세 조정을 위한 몇 가지 지침이며 요약은 그림 4.11에 나와 있습니다.

- 소스 모델과 대상 모델 모두 하위 및 중간 레이어를 공유해야 합니다. 상위 레이어만 교체하거나 다시 초기화됩니다.
- 교체하거나 다시 초기화할 레이어의 수는 두 가지 요인에 따라 달라집니다.
  1. 소스 작업과 대상 작업 간의 유사성; 작업이 유사할수록 다시 초기화해야 하는 레이어가 적습니다.
  2. 소스 데이터셋과 대상 데이터셋 크기의 차이; 차이가 작을수록 더 많은 레이어를 교체하거나 다시 초기화해야 합니다.
- 미세 조정은 소스 데이터셋이 대상 데이터셋보다 훨씬 클 때 가장 잘 작동합니다. 대상 데이터셋이 같거나 더 큰 경우 대상 작업에 대해 새 모델을 훈련하는 것이 더 나은 접근 방식입니다.
- 이러한 모델을 미세 조정하기 위한 초기 LR은 사전 훈련된 레이어에 대해 원래 모델을 훈련하는 데 사용된 초기 LR보다 10-100배 작아야 합니다. 교체되거나 다시 초기화된 레이어에는 일반 LR을 사용해야 합니다.
- 원래의 더 큰 데이터셋에 대한 동일한 데이터 전처리 기술을 미세 조정 및 검증에 사용되는 데이터셋에 적용해야 합니다.

그림 4.11: 언제 무엇을 미세 조정해야 하는지에 대한 상위 수준 지침. 새 작업의 데이터셋이 원래 데이터셋과 유사할 때는 마지막 상위 레이어만 재훈련해야 합니다. 데이터셋이 다르면 더 많은 레이어를 훈련해야 합니다. 새 작업의 데이터셋이 충분히 크면 전체 모델을 재훈련하는 것이 가장 좋습니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000010_6fae5f2f8b75ca90711b8ec6bf721c631b04ca0b47f6257dedf904613b284b2e.png)

| 대규모 데이터셋     |                                                          | 상위 레이어 훈련   | 유사함   |
|-------------------|----------------------------------------------------------|----------------------|-----------|
| 다른 데이터셋 | 모든 레이어 훈련 상위 레이어 훈련; 나머지는 미세 조정 | 상위 레이어 훈련   | 데이터셋   |

간단한 예로, 다음 단계는 개 vs 고양이 분류기를 설계하고 훈련하는 데 사용할 수 있습니다(실제로는 더 최근 모델이 더 나은 통계적 성능을 가집니다).

1. 그림 4.12와 같이 사전 훈련된 VGG16 모델의 마지막 레이어를 $4096 \times 1000$에서 $4096 \times 2$로 교체합니다. 소스 데이터셋에는 1000개의 클래스가 있지만 이 작업에는 2개만 있기 때문입니다.
2. 마지막 레이어를 초기화하고 나머지 레이어에는 사전 훈련된 가중치를 사용합니다.
3. 마지막 레이어를 제외한 모든 레이어를 동결(freeze)하거나 LR을 100배 줄입니다.
4. 대상 데이터셋으로 토폴로지를 훈련합니다(최신 노트북은 이 작업에 충분한 연산 능력을 가지고 있습니다).

미세 조정은 가중치 가지치기 또는 양자화(6장에서 논의됨) 후와 같이 모델을 일부 수정한 후에도 일반적으로 사용됩니다. 도메인 적응(domain adaptation), {zero, one, few}-shot 학습, 멀티태스크 학습과 같은 다른 유형의 전이 학습 기술이 있습니다 [PY10, KL19, WYK+19, Rud17]. 이러한 기술은 산업 채택이 제한적입니다.

## 4.7 제한된 메모리로 훈련하기

훈련에는 서빙보다 훨씬 더 많은 메모리가 필요합니다. 순전파 반복 동안 역전파 중에 그래디언트를 계산하려면 모든 레이어의 활성화를 저장해야 합니다. 메모리 용량은 대규모 모델을 훈련할 때, 특히 GPU 및 가속기에서 병목 현상이 될 수 있습니다. 이 섹션에서는 메모리 병목 현상을 완화하는 기술을 검토합니다.

가장 간단한 기술은 배치 크기를 줄이는 것입니다. 활성화의 크기는 배치 크기에 비례합니다. 그러나 배치 크기가 32 미만인 경우 배치 정규화 레이어가 있는 모델에는 권장되지 않습니다. 해결책은 배치 정규화를 그룹 정규화 기술로 교체하고 마이크로 배치를 사용하는 것입니다.

그다음으로 좋은 기술은 2000년에 소개되었고 최근 학계에서 주목받고 있으며 2016년 기술이 다시 부상한 후 업계에서 일부 채택되고 있는 **그래디언트 체크포인트(gradient checkpoint)**입니다 [GW00, CXZ+16]. 그래디언트 체크포인트는 추가 계산을 희생하여 메모리 요구 사항을 줄입니다. 모든 레이어에 걸쳐 활성화를 저장하는 대신 일부 레이어의 활성화만 저장합니다. 예를 들어, 100개의 레이어가 있는 모델은 10개의 레이어마다 활성화를 저장할 수 있습니다. 이러한 레이어를 체크포인트라고 하며 체크포인트 사이의 레이어 그룹은 세그먼트입니다. 역전파 동안 특정 세그먼트에 대해 활성화가 다시 계산됩니다. 이를 다시 계산하는 과정을 **재물질화(rematerialization)**라고 합니다. 주어진 시간에 메모리에 있는 활성화는 (1) 체크포인트 활성화 및 (2) 한 세그먼트에 대한 활성화입니다. 100개의 레이어와 10개의 체크포인트가 있는 예에서는 모든 활성화의 약 20%만 한 번에 저장됩니다. 계산 비용은 추가적인 순전파입니다. 컴퓨팅 용량이 높고 메모리가 제한된 GPU 또는 가속기에서 이 추가 컴퓨팅은 호스트에서 활성화를 저장하고 가져오는 것보다 시간과 전력이 덜 필요할 수 있습니다.

실제로 체크포인트를 균일하게 나누는 것은 좋은 관행이 아닙니다. 활성화의 총 크기와 각 세그먼트의 순전파 계산 비용은 크게 다를 수 있습니다. 또한 스킵 연결(skip connection) 내의 체크포인트는 피해야 합니다. 세그먼트 전체에 걸쳐 활성화의 총 크기를 균등하게 나누는 최적의 체크포인트 레이어 수를 선택하는 것은 NP-완전 문제입니다. Jain 등은 특정 하드웨어 타겟에 대한 체크포인트를 찾는 시스템인 Checkmate를 도입했습니다. Checkmate는 적절한 체크포인트를 찾기 위해 하드웨어 비용 모델과 결합된 기성 혼합 정수 선형 프로그램 솔버를 사용합니다 [JJN+19].

또 다른 기술은 활성화를 32비트가 아닌 16비트로 저장하는 것입니다. 이는 메모리 및 대역폭 사용량을 최대 2배까지 줄입니다. NN은 노이즈에 강하며 절반의 비트를 가진 활성화를 사용하여 그래디언트를 계산해도 일반적으로 통계적 성능에 영향을 미치지 않습니다. 관련 기술은 압축된 활성화를 저장하는 것입니다 [JJN+19].

마지막 기술은 **심층 평형(Deep Equilibrium, DEQ)**으로, 필요한 메모리를 일정하게 유지하면서 모델의 깊이를 변경할 수 있습니다. 메모리는 단일 레이어의 활성화와 동일합니다 [BKK19]. DEQ는 추가 계산을 희생하여 메모리 요구 사항을 줄입니다. 이 기술은 아직 업계에서 채택되지 않았습니다.

이 장에서는 일반화되고 과소적합 및 과적합을 방지하는 모델을 훈련하는 방법을 설명했습니다. 다양한 레이어에서 가중치를 초기화하는 방법을 설명했습니다. SGD를 자세히 설명하고 다양한 변형을 검토했습니다. 소규모에서 중간 규모 배치의 경우 Ranger를, 대규모 배치의 경우 RangerLARS를 사용할 것을 권장하며, 훈련이 처음인 경우 문서화가 잘 되어 있고 시작하기 간단한 Adam을 권장합니다. 우리는 대규모 배치에서 작업하면 하드웨어 활용도가 높아질 수 있지만 작은 배치가 더 잘 일반화될 수 있음을 지적하고 배치 크기 선택에 대한 지침을 제공했습니다. 우리는 역전파 알고리즘을 하드웨어에서 특수 행렬 곱셈기의 필요성을 부여하는 일련의 곱셈과 덧셈으로 분해했습니다. 토폴로지 설계에 대한 지침을 제공하고 데이터 과학자가 설계 및 디버그 단계에서 사용해야 하는 하이퍼파라미터를 권장했습니다. 추가 컴퓨팅을 희생하여 훈련 단계에서 메모리 용량 병목 현상을 완화하는 방법을 설명했습니다. 데이터셋이 작은 회사의 경우 기존 모델을 수정하고 특정 작업에 대해 미세 조정할 것을 권장했습니다. 다음 장에서는 다양한 컴퓨팅 노드에 걸쳐 계산 및 메모리 요구 사항을 분산하여 훈련을 가속화하는 방법을 살펴봅니다.

그림 4.12: 원래 ImageNet1K 데이터셋으로 훈련된 개 vs 고양이 분류 작업을 위해 VGG-16 모델을 미세 조정합니다.

![Image](/assets/img/posts/2026-02-05-DeepLearningSystems_chapter4_한국어/image_000011_82a48e0a17ff2b5a566a0f932dfa37e1c503680893f711a68ea1f4af8c3fd556.png)